package net.sf.jclec.problem.classification.algorithm.bojarczuk;

import java.util.Comparator;
import java.lang.Math;

import net.sf.jclec.IFitness;
import net.sf.jclec.IIndividual;
import net.sf.jclec.base.AbstractParallelEvaluator;
import net.sf.jclec.fitness.SimpleValueFitness;
import net.sf.jclec.fitness.ValueFitnessComparator;
import net.sf.jclec.problem.classification.base.Rule;
import net.sf.jclec.problem.classification.syntaxtree.SyntaxTreeRuleIndividual;
import net.sf.jclec.problem.util.dataset.IDataset;
import net.sf.jclec.problem.util.dataset.instance.IInstance;
import net.sf.jclec.problem.util.dataset.attribute.CategoricalAttribute;
import net.sf.jclec.problem.util.dataset.metadata.IMetadata;

/**
 * Evaluator for Bojarczuk et al. 2004 - A constrained-syntax genetic programming system for discovering classification rules: application to medical data sets<p/>
 *
 * The fitness function evaluates the confusion matrix for each of the data classes.
 * The predicted class whose sensitivity and specificity is maximal is selected as the consequent of the rule.
 * Finally, the fitness is weighted as regards of the length of the rule (number of nodes).
 * Therefore, the evolutionary process is biased to evolve accurate, simple and more comprehensible rules.
 *
 * @author Amelia Zafra
 * @author Sebastian Ventura
 * @author Jose M. Luna
 * @author Alberto Cano
 * @author Juan Luis Olmo
 */

public class BojarczukEvaluator extends AbstractParallelEvaluator
{
	/////////////////////////////////////////////////////////////////
	// --------------------------------------- Serialization constant
	/////////////////////////////////////////////////////////////////

	/** Generated by Eclipse */

	private static final long serialVersionUID = 3613350191235561000L;

	/////////////////////////////////////////////////////////////////
	// --------------------------------------------------- Properties
	/////////////////////////////////////////////////////////////////

	/** Train Dataset */

	protected IDataset dataset;

	/** Maximize the fitness function */

	private boolean maximize = false;

	/** Maximum derivation size */

	protected int maxDerivSize;

	protected String fitness;

	/** Fitness comparator */

	protected transient ValueFitnessComparator comparator = new ValueFitnessComparator(!maximize);

	/////////////////////////////////////////////////////////////////
	// ------------------------------------------------- Constructors
	/////////////////////////////////////////////////////////////////

	/**
	 * Empty constructor.
	 */

	public BojarczukEvaluator()
	{
		super();
	}

	/////////////////////////////////////////////////////////////////
	// ------------------------------- Getting and setting properties
	/////////////////////////////////////////////////////////////////

	/**
	 * Get the dataset
	 *
	 * @return dataset
	 */

	public IDataset getDataset()
	{
		return dataset;
	}

	/**
	 * Set the dataset
	 *
	 * @param dataset the dataset
	 */

	public void setDataset(IDataset dataset)
	{
		this.dataset = dataset;
	}

	public void setFitness(String value) {
		this.fitness = value;
	}

	public String getFitness() {
		return fitness;
	}

	/**
	 * Get the maximum derivation size
	 *
	 * @return maxDerivSize
	 */
	public int getMaxDerivSize()
	{
		return maxDerivSize;
	}

	/**
	 * Set the maximum derivation size
	 *
	 * @param maxDerivSize maximum derivation size
	 */
	public void setMaxDerivSize(int maxDerivSize)
	{
		this.maxDerivSize = maxDerivSize;
	}

	/////////////////////////////////////////////////////////////////
	// ------------------------ Overwriting AbstractEvaluator methods
	/////////////////////////////////////////////////////////////////

	/**
	 * Evaluates the individual and compute it fitness
	 *
	 * @param individual Individual to evaluate
	 */

	protected void evaluate(IIndividual individual)
	{
		Rule rule = (Rule) ((SyntaxTreeRuleIndividual) individual).getPhenotype();

		int[] tp, fp, tn, fn;

		IMetadata metadata = getDataset().getMetadata();
		CategoricalAttribute catAttribute = (CategoricalAttribute) metadata.getAttribute(metadata.getClassIndex());
		int numClasses = catAttribute.getCategories().size();

		tp = new int [numClasses];
		tn = new int [numClasses];
		fn = new int [numClasses];
		fp = new int [numClasses];

		double[] valorOMAE = new double [numClasses];

		int num_instancias = dataset.numberOfInstances();


		if (!fitness.equals("DEFAULT")) {

			//Calculate the confusion matrix for each class
			for(IInstance instance : dataset.getInstances())
			{

				if((Boolean) rule.covers(instance))
				{

					double value = instance.getValue(metadata.getClassIndex());

					for(int i=0; i<numClasses; i++) {
						valorOMAE[i] += Math.abs(i - value);
					}
				}
				else
				{
					double value = instance.getValue(metadata.getClassIndex());
					valorOMAE[(int) value] += numClasses;
				}
			}


			//Calculate the fitness for each class
			double se = -1, sp = 1, sy;
			double seAux, spAux;
			int bestClass = -1;
			double bestOMAEAux = Double.POSITIVE_INFINITY;

			for(int i=0; i<numClasses; i++)
			{

				valorOMAE[i] /= num_instancias;

				if (valorOMAE[i] < bestOMAEAux) {
					bestClass = i;
					bestOMAEAux = valorOMAE[i];

				}

			}

			// Assign as consequent the class that reports the best fitness
			rule.setConsequent(bestClass);


			double OMAE_final = 0.0;

			double MMAE = 0.0;

			for (int i = 0; i < numClasses; i++) {
				OMAE_final += valorOMAE[i];

				// para MMAE
				if (valorOMAE[i] > MMAE) {
					MMAE = valorOMAE[i];
				}

			}

			// para AMAE
			if (fitness.equals("AMAE"))
			 	OMAE_final /= (double)numClasses;

			if (fitness.equals("MMAE"))
				individual.setFitness(new SimpleValueFitness(MMAE));
			else
				individual.setFitness(new SimpleValueFitness(OMAE_final));


		} // fin if OMAE AMAE y MMAE
		else {
				//Calculate the confusion matrix for each class
			for(IInstance instance : dataset.getInstances())
			{
				if((Boolean) rule.covers(instance))
				{
					double value = instance.getValue(metadata.getClassIndex());
					tp[(int) value]++;
					for(int i=0; i<numClasses; i++)
						if(((int) value) != i)
							fp[i]++;
				}
				else
				{
					double value = instance.getValue(metadata.getClassIndex());

					fn[(int) value]++;
					for(int i=0; i<numClasses; i++)
						if(((int) value) != i)
							tn[i]++;
				}
			}

			//Calculate the fitness for each class
			double se = -1, sp = 1, sy;
			double seAux, spAux;
			int bestClass = -1;

			for(int i=0; i<numClasses; i++)
			{
				if(tp[i]+fn[i] == 0)
					seAux = 1;
				else
					seAux = (double) tp[i]/(tp[i]+fn[i]);

				if(tn[i]+fp[i] == 0)
					spAux = 1;
				else
					spAux = (double) tn[i]/(tn[i]+fp[i]);

				if(seAux*spAux == se*sp)
					bestClass = i;

				if(seAux*spAux > se*sp)
				{
					se = seAux;
					sp = spAux;
					bestClass = i;
				}
			}

			// Assign as consequent the class that reports the best fitness
			rule.setConsequent(bestClass);

			double numnodes = rule.getAntecedent().size();

			sy = (getMaxDerivSize() - 0.5*numnodes -0.5)/(getMaxDerivSize()-1);

			individual.setFitness(new SimpleValueFitness(se*sp*sy));
		}

	}

	/**
	 * {@inheritDoc}
	 */

	public Comparator<IFitness> getComparator()
	{
		return comparator;
	}
}
